{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e142e1-89ee-48d5-95d9-1821d0d59c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bird over animal\n",
      "insect over animal\n",
      "clothing and clothing_accessory, remove:\n",
      "['bowtie' 'cummerbund']\n",
      "dessert over drink\n",
      "dessert over food\n",
      "fruit over food\n",
      "food and plant, remove:\n",
      "['seed']\n",
      "vegetable over food\n",
      "fruit and vegetable, remove:\n",
      "['tomato']\n",
      "furniture and home_decor, remove:\n",
      "['coat_rack']\n",
      "kitchen_appliance and kitchen_tool, remove:\n",
      "['kettle']\n",
      "kitchen_tool and tool, remove:\n",
      "['funnel' 'icepick']\n",
      "office_supply and tool, remove:\n",
      "['letter_opener']\n",
      "sports_equipment and tool, remove:\n",
      "['bungee']\n",
      "sports_equipment and toy, remove:\n",
      "['frisbee']\n",
      "tool and weapon, remove:\n",
      "['trident']\n",
      "toy and vehicle, remove:\n",
      "['scooter']\n",
      "toy and weapon, remove:\n",
      "['boomerang']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import scipy.io\n",
    "\n",
    "things_stim_path = '/user_data/mmhender/things/'\n",
    "things_images_root = os.path.join(things_stim_path, 'Images')\n",
    "\n",
    "# def process_concepts():\n",
    "\n",
    "filename = os.path.join(things_stim_path,'things_concepts.tsv')\n",
    "\n",
    "df = pd.read_csv(filename, sep='\\t')\n",
    "concept_list = np.array(df['Word'])\n",
    "ids_list = np.array(df['uniqueID'])\n",
    "concept_list = [c.replace(' ', '_') for c in concept_list]\n",
    "n_concepts = len(concept_list)\n",
    "# concepts are the fine-grained/basic level names\n",
    "\n",
    "info_folder = os.path.join(things_stim_path,'27 higher-level categories')\n",
    "categ_names = scipy.io.loadmat(os.path.join(info_folder, 'categories.mat'))['categories'][0]\n",
    "categ_names = [categ_names[ii][0] for ii in range(len(categ_names))]\n",
    "categ_names = [categ.replace(' ', '_') for categ in categ_names]\n",
    "n_categ = len(categ_names)\n",
    "# categories are the high-level/superordinate names\n",
    "\n",
    "# load the \"bottom-up\" (human-generated) groupings\n",
    "dat = scipy.io.loadmat(os.path.join(info_folder, 'category_mat_bottom_up.mat'))\n",
    "cmat = dat['category_mat_bottom_up']\n",
    "\n",
    "# there is a swap in this labeling betweeen \"hot-air balloon\" and \"hot chocolate\"\n",
    "# (maybe a typo?)\n",
    "# i am manually switching them here\n",
    "cmat_fixed = copy.deepcopy(cmat)\n",
    "tmp = copy.deepcopy(cmat[801,:])\n",
    "cmat_fixed[801,:] = cmat[803,:]\n",
    "cmat_fixed[803,:] = tmp\n",
    "\n",
    "concepts_each_categ = [np.array(concept_list)[cmat_fixed[:,ii]==1] for ii in range(n_categ)]\n",
    "\n",
    "# now going to fix these a bit to get rid of anything ambiguous\n",
    "cmat_adjusted = copy.deepcopy(cmat_fixed).astype(bool) \n",
    "\n",
    "# removing any duplicate concept names here (these are ambiguous meaning words like bat)\n",
    "un, counts = np.unique(concept_list, return_counts=True)\n",
    "duplicate_conc = un[counts>1]\n",
    "duplicate_conc_inds = np.where([conc in duplicate_conc for conc in concept_list])\n",
    "cmat_adjusted[duplicate_conc_inds,:] = False\n",
    "\n",
    "# remove any concepts that have the same name as one of the categories (for example \"fruit\")\n",
    "duplicate_inds = np.where([conc in categ_names for conc in concept_list])[0]\n",
    "cmat_adjusted[duplicate_inds,:] = False\n",
    "\n",
    "# deciding how to resolve overlap between categories. \n",
    "# set these as categories to \"prioritize\" when the same concept occurs in \n",
    "# another category. \n",
    "categories_prioritize = ['bird','insect','dessert','fruit','vegetable']\n",
    "\n",
    "for cc1 in range(n_categ):\n",
    "\n",
    "    for cc2 in np.arange(cc1+1, n_categ):\n",
    "\n",
    "        overlap = cmat_adjusted[:,cc1] & cmat_adjusted[:,cc2]\n",
    "\n",
    "        cat1 = categ_names[cc1]\n",
    "        cat2 = categ_names[cc2]\n",
    "\n",
    "        if np.sum(overlap)>0:\n",
    "\n",
    "            if (cat1 in categories_prioritize) and (cat2 not in categories_prioritize):\n",
    "                # remove concept from the not-prioritized category\n",
    "                print('%s over %s'%(cat1, cat2))\n",
    "                cmat_adjusted[overlap,cc2] = False\n",
    "            elif (cat2 in categories_prioritize) and (cat1 not in categories_prioritize):\n",
    "                print('%s over %s'%(cat2, cat1))\n",
    "                cmat_adjusted[overlap,cc1] = False        \n",
    "            else:\n",
    "                # if neither is prioritized, don't use the concept at all\n",
    "                print('%s and %s, remove:'%(cat1, cat2))\n",
    "                print(np.array(concept_list)[overlap])\n",
    "                cmat_adjusted[overlap,cc1] = False\n",
    "                cmat_adjusted[overlap,cc2] = False\n",
    "\n",
    "concepts_each_categ_adj = [np.array(concept_list)[cmat_adjusted[:,ii]==1] for ii in range(n_categ)]\n",
    "ids_each_categ = [np.array(ids_list)[cmat_adjusted[:,ii]==1] for ii in range(n_categ)]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
