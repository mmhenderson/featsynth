{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b224f975-68a0-418f-8053-88debb8a1ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt     # type: ignore\n",
    "\n",
    "nsd_stim_path = '/user_data/mmhender/nsd/stimuli/'\n",
    "save_stim_path = '/user_data/mmhender/stimuli/'\n",
    "root = os.path.dirname(os.getcwd())\n",
    "\n",
    "sys.path.insert(0,root)\n",
    "\n",
    "import utilities\n",
    "import model_spatial\n",
    "import optimize\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8b7d454-8a72-4654-bc49-de13d1f35efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/user_data/mmhender/texture_synthesis'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d54b6b58-8beb-45eb-8b8f-a12ecbdf30fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "\n",
      "loading image info from /user_data/mmhender/nsd/stimuli/Indep_set_info.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "info_fn = os.path.join(nsd_stim_path, 'Indep_set_info.csv')\n",
    "print('\\nloading image info from %s\\n'%info_fn)\n",
    "info_df = pd.read_csv(info_fn, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e5c4b63-aafd-484c-91c0-0744bc71ad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing target image /lab_data/tarrlab/common/datasets/COCO/train2017/000000300147.jpg\n"
     ]
    }
   ],
   "source": [
    "ii=1000;\n",
    "\n",
    "target_image_filename = info_df['filename_raw'].iloc[ii]\n",
    "print('processing target image %s'%target_image_filename)\n",
    "sys.stdout.flush()\n",
    "\n",
    "cocoid = target_image_filename.split('/')[-1].split('.')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39ec6dac-4930-4a52-9404-5e4725011bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class a():\n",
    "    def __init__(self, n_ims_do=10, n_steps=10, debug=0):\n",
    "        self.n_ims_do = n_ims_do\n",
    "        self.n_steps = n_steps\n",
    "        self.debug = debug\n",
    "args = a()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eef4723-7307-4bd0-ac44-5aeb14aecda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.lr = 1.0\n",
    "args.max_iter = 20\n",
    "args.checkpoint_every = 1\n",
    "args.n_steps = 100\n",
    "args.rndseed = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dbe9e1fa-d542-498b-ad59-c78d5c1a8da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.which_grid=2\n",
    "args.n_grid_eachside=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee0bd226-ec4c-4ad9-a2de-2feba629b86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading overlap from /user_data/mmhender/texture_synthesis/grid_overlap/vgg19_gridoverlap_grid2_1x1_Conv1.npy\n",
      "loading overlap from /user_data/mmhender/texture_synthesis/grid_overlap/vgg19_gridoverlap_grid2_1x1_MaxPool1.npy\n",
      "loading overlap from /user_data/mmhender/texture_synthesis/grid_overlap/vgg19_gridoverlap_grid2_1x1_MaxPool2.npy\n",
      "loading overlap from /user_data/mmhender/texture_synthesis/grid_overlap/vgg19_gridoverlap_grid2_1x1_MaxPool3.npy\n",
      "loading overlap from /user_data/mmhender/texture_synthesis/grid_overlap/vgg19_gridoverlap_grid2_1x1_MaxPool4.npy\n"
     ]
    }
   ],
   "source": [
    "layer_names_uppercase = ['Conv1','MaxPool1','MaxPool2','MaxPool3','MaxPool4']\n",
    "n_layers = len(layer_names_uppercase)\n",
    "overlap_each_layer = []\n",
    "for ll in range(n_layers):\n",
    "\n",
    "    fn = os.path.join(root,'grid_overlap','vgg19_gridoverlap_grid%d_%dx%d_%s.npy'%(args.which_grid,\n",
    "                                                                           args.n_grid_eachside, \n",
    "                                                                    args.n_grid_eachside, \n",
    "                                                                    layer_names_uppercase[ll]))\n",
    "    print('loading overlap from %s'%fn)\n",
    "    overlap = np.load(fn)\n",
    "    overlap_each_layer.append(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87059afd-9c9e-4454-bf62-15a336ea33bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f9fc67e90b8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.pcolormesh(overlap_each_layer[0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "157c4a71-956c-45f5-a43b-42a35031a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load target image to use in synthesis (different preproc than above)\n",
    "target_image = utilities.preprocess_image(\n",
    "    utilities.load_image(target_image_filename)\n",
    ")\n",
    "\n",
    "important_layers = ['relu1_1', 'pool1','pool2','pool3','pool4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "19812396-3f1d-4bf9-bb08-f49d705f40a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making texture for layers:\n",
      "['relu1_1', 'pool1', 'pool2', 'pool3', 'pool4']\n"
     ]
    }
   ],
   "source": [
    "ll=4;\n",
    "\n",
    "layers_match = important_layers[0:ll+1]\n",
    "spatial_weights_use = overlap_each_layer[0:ll+1]\n",
    "print('making texture for layers:')\n",
    "print(layers_match)\n",
    "sys.stdout.flush()\n",
    "\n",
    "model_path = os.path.join(root, 'models','VGG19_normalized_avg_pool_pytorch')\n",
    "        \n",
    "net = model_spatial.Model(model_path, device, target_image, \\\n",
    "                          important_layers=layers_match, \\\n",
    "                          spatial_weights_list = spatial_weights_use, \n",
    "                          do_sqrt = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "184eae83-1226-472c-a84d-e33705ede037",
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_matrices = net.gram_loss_hook.target_gram_matrices\n",
    "gram_numpy = [g.detach().cpu().numpy().astype(np.float32) for g in gram_matrices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "97272387-80db-4b5a-a2ee-c6728cc80149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gram_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be844b77-29cf-4070-b193-44cf176097af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352256,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_feats_concat = np.concatenate([g.ravel() for g in gram_numpy], axis=0)\n",
    "gram_feats_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f17b9c0-ed87-49b6-897e-03d17e19c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(os.getcwd(),'test2.npy')\n",
    "np.save(savename, gram_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e57f0a98-662c-4a1e-8901-9fbd35a977d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<model_spatial.Model at 0x7f9fc6b800f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def gram_matrix_spatweighted(activations: torch.Tensor, spatial_weights: torch.Tensor = None, do_sqrt=True) -> torch.Tensor:\n",
    "    b, n, x, y = activations.size()\n",
    "    # print((b,n,x,y))\n",
    "    activation_matrix = activations.view(b * n, x * y)\n",
    "    \n",
    "    if do_sqrt:\n",
    "        # print('doing sqrt')\n",
    "        activation_matrix_weighted = activation_matrix * torch.sqrt(spatial_weights[None,:])\n",
    "    else:\n",
    "        # print('skipping sqrt')\n",
    "        activation_matrix_weighted = activation_matrix * spatial_weights[None,:]\n",
    "    \n",
    "    G = torch.mm(activation_matrix_weighted, activation_matrix_weighted.t())    # gram product\n",
    "    return G.div(b * n * x * y)     # normalization\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(\n",
    "        self, path: str, device: torch.device, target_image: torch.Tensor,\n",
    "        important_layers: List[str] = [\n",
    "            'relu1_1', 'pool1', 'pool2', 'pool3', 'pool4'\n",
    "        ],\n",
    "        spatial_weights_list: List[torch.Tensor] = None,\n",
    "        do_sqrt=True, \n",
    "    ):\n",
    "        self.net = utilities.load_model(path).to(device).eval()\n",
    "        self.device = device\n",
    "        self.target_image = target_image.to(device)\n",
    "        self.layer_weights = layer_weights\n",
    "        self.important_layers = important_layers\n",
    "        self.do_sqrt=do_sqrt\n",
    "        # print(self.important_layers)\n",
    "        \n",
    "        self.spatial_weights_list = [torch.Tensor(sw).to(self.device) for sw in spatial_weights_list]\n",
    "        if self.spatial_weights_list is not None:\n",
    "            self.n_total_grid = self.spatial_weights_list[0].shape[0]\n",
    "            assert(len(self.spatial_weights_list)==len(self.important_layers))\n",
    "            \n",
    "        # extract Gram matrices of the target image\n",
    "        \n",
    "        gram_hook = GramHook(self.spatial_weights_list, do_sqrt = self.do_sqrt)\n",
    "        gram_hook_handles = []\n",
    "        \n",
    "        for name, layer in self.net.named_children():\n",
    "            if name in self.important_layers:\n",
    "               \n",
    "                handle = layer.register_forward_hook(gram_hook)\n",
    "                gram_hook_handles.append(handle)\n",
    "            \n",
    "        self.net(self.target_image)\n",
    "\n",
    "        # print('gram matrices:')\n",
    "        # print(len(gram_hook.gram_matrices), [gm.shape for gm in gram_hook.gram_matrices])\n",
    "        # register Gram loss hook\n",
    "        self.gram_loss_hook = GramLossHook(\n",
    "            gram_hook.gram_matrices, self.layer_weights, \\\n",
    "            self.important_layers, self.spatial_weights_list, do_sqrt = self.do_sqrt\n",
    "        )\n",
    "        # print('sizes of gram matrices')\n",
    "        # for ii, mat in enumerate(gram_hook.gram_matrices):\n",
    "        #     print(ii, mat.shape)\n",
    "        for handle in gram_hook_handles:    # Gram hook is not needed anymore\n",
    "            handle.remove()\n",
    "\n",
    "        for name, layer in self.net.named_children():\n",
    "            if name in self.important_layers:\n",
    "                # print('adding loss hook for %s'%name)\n",
    "                handle = layer.register_forward_hook(self.gram_loss_hook)\n",
    "\n",
    "        # print([name for [name, l] in self.net.named_children()])\n",
    "        # remove unnecessary layers\n",
    "        i = 0\n",
    "        for name, layer in self.net.named_children():\n",
    "            if name == important_layers[-1]:\n",
    "                break\n",
    "            i += 1\n",
    "        self.net = self.net[:(i + 1)]\n",
    "        # print([name for [name, l] in self.net.named_children()])\n",
    "        \n",
    "    def __call__(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        self.gram_loss_hook.clear()\n",
    "\n",
    "        return self.net(image)\n",
    "\n",
    "    def get_loss(self) -> torch.Tensor:\n",
    "        # return sum(self.gram_loss_hook.losses)\n",
    "        return torch.stack(self.gram_loss_hook.losses, dim=0).sum(dim=0)\n",
    "\n",
    "    \n",
    "class GramHook:\n",
    "    def __init__(self, \n",
    "                 spatial_weights_list: List[torch.Tensor],\n",
    "                 do_sqrt=True):\n",
    "        self.gram_matrices = []\n",
    "        self.spatial_weights_list = spatial_weights_list\n",
    "        self.layer_counter = -1;\n",
    "        self.do_sqrt=do_sqrt\n",
    "        \n",
    "    def __call__(\n",
    "        self, layer: torch.nn.Module, layer_in: Tuple[torch.Tensor],\n",
    "        layer_out: torch.Tensor\n",
    "    ):\n",
    "        self.layer_counter+=1\n",
    "        ll = self.layer_counter\n",
    "        n_grid_total = self.spatial_weights_list[0].shape[0]\n",
    "        for gg in range(n_grid_total):\n",
    "            spatial_weights = self.spatial_weights_list[ll][gg,:]\n",
    "            # print('size of spatial weights:')\n",
    "            # print(spatial_weights.shape)\n",
    "            gram_matrix = gram_matrix_spatweighted(layer_out.detach(), spatial_weights, self.do_sqrt)\n",
    "            # print('size of gram matrix:')\n",
    "            # print(gram_matrix.shape)\n",
    "            self.gram_matrices.append(gram_matrix)\n",
    "\n",
    "class GramLossHook:\n",
    "    def __init__(\n",
    "        self, target_gram_matrices: List[torch.Tensor],\n",
    "        layer_weights: List[float], layer_names: List[str],\n",
    "        spatial_weights_list: List[torch.Tensor],\n",
    "        do_sqrt=True, \n",
    "    ):\n",
    "        self.target_gram_matrices = target_gram_matrices\n",
    "        self.layer_weights = [\n",
    "            weight * (1.0 / 4.0) for weight in layer_weights\n",
    "        ]\n",
    "        self.layer_names = layer_names\n",
    "        self.losses: List[torch.Tensor] = []\n",
    "        self.spatial_weights_list = spatial_weights_list\n",
    "        self.layer_counter = -1;\n",
    "        self.do_sqrt=do_sqrt\n",
    "        \n",
    "    def __call__(\n",
    "        self, layer: torch.nn.Module, layer_in: Tuple[torch.Tensor],\n",
    "        layer_out: torch.Tensor\n",
    "    ):\n",
    "        self.layer_counter+=1\n",
    "        ll = self.layer_counter\n",
    "        # print('layer_counter = %d'%self.layer_counter)\n",
    "        assert ll < len(self.layer_weights)\n",
    "        assert ll < len(self.target_gram_matrices)\n",
    "        assert not torch.isnan(layer_out).any()\n",
    "\n",
    "        n_grid_total = self.spatial_weights_list[0].shape[0]\n",
    "        for gg in range(n_grid_total):\n",
    "            # print('len of layer_names: %d'%len(self.layer_names))\n",
    "            \n",
    "            tt = ll * n_grid_total + gg\n",
    "            # print(ll, gg, tt)\n",
    "            opt_gram_matrix = gram_matrix_spatweighted(layer_out, \n",
    "                                                       self.spatial_weights_list[ll][gg,:],\n",
    "                                                       self.do_sqrt)\n",
    "            \n",
    "            # print(opt_gram_matrix.shape)\n",
    "            # print(self.target_gram_matrices[tt].shape)\n",
    "            loss = self.layer_weights[ll] * (\n",
    "                (opt_gram_matrix - self.target_gram_matrices[tt])**2\n",
    "            ).sum()\n",
    "            # print(tt, len(self.losses), loss)\n",
    "            self.losses.append(loss)\n",
    "\n",
    "    def clear(self):\n",
    "        self.losses = []\n",
    "        self.layer_counter=-1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
