{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7e009a02-ece8-4b6f-a2fa-0c3a59f6154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "things_root = '/user_data/mmhender/stimuli/things/'\n",
    "project_root = '/user_data/mmhender/featsynth/'\n",
    "stimuli_folder = '/user_data/mmhender/stimuli/featsynth/images_comb64/'\n",
    "ecoset_info_path = '/user_data/mmhender/stimuli/ecoset_info/'\n",
    "\n",
    "sys.path.insert(0, '/user_data/mmhender/featsynth/code/')\n",
    "from utils import expt_utils\n",
    "\n",
    "expt_name = 'fmri_pilot2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "da5171e1-23fe-44e9-bef1-fbf97f0c3d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_expt_designs import make_fmri_pilot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a143ae5c-cf99-4cd4-a764-15abfae67d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_fmri_pilot2.make_trial_info(rndseed=756756)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "18295e3a-4fdf-4e18-8569-a87eb0da63d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/user_data/mmhender/stimuli/featsynth/images_comb64/synth_losses_all.npy\n"
     ]
    }
   ],
   "source": [
    "# using here the same set of categories that we chose from ecoset.\n",
    "# 64 basic categories in 8 superordinate groups.\n",
    "fn = os.path.join(ecoset_info_path, 'categ_use_ecoset.npy')\n",
    "info = np.load(fn, allow_pickle=True).item()\n",
    "basic_names = list(info['binfo'].keys())\n",
    "super_names = list(info['sinfo'].keys())\n",
    "\n",
    "# load info about which images to use\n",
    "# made this in make_featsynth_images_comb64.py\n",
    "fn = os.path.join(stimuli_folder, 'synth_losses_all.npy')\n",
    "print(fn)\n",
    "l = np.load(fn, allow_pickle=True).item()\n",
    "\n",
    "categ_sets = [super_names]\n",
    "concept_sets = [[info['sinfo'][sname]['basic_names'] for sname in super_names]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8505ef0-e9ac-42d4-a816-a40ac2b9f52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['beetle', 'bee', 'butterfly', 'grasshopper', 'caterpillar', 'ant'],\n",
       "  ['dog', 'lion', 'horse', 'squirrel', 'elephant', 'cow'],\n",
       "  ['pea', 'corn', 'pumpkin', 'onion', 'cabbage', 'lettuce'],\n",
       "  ['grape', 'cherry', 'raspberry', 'apple', 'pear', 'banana'],\n",
       "  ['pencil', 'knife', 'axe', 'broom', 'hammer', 'shovel'],\n",
       "  ['bell', 'guitar', 'piano', 'drum', 'violin', 'trumpet'],\n",
       "  ['table', 'bench', 'couch', 'television', 'bed', 'chair'],\n",
       "  ['ship', 'train', 'airplane', 'truck', 'car', 'bus']]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_sets = [[c[0:6] for c in concept_sets[0]]]\n",
    "concept_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ed33d2fc-839a-451e-b3f6-dc115ac580bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out trial conditions/counts\n",
    "n_categ_use = len(categ_sets[0])\n",
    "n_concepts_use = len(concept_sets[0][0])\n",
    "# n_ex_use = len(image_name_sets[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c638e2d4-19a1-47db-918c-6fa01aab3aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 6)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_categ_use, n_concepts_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809cb800-3cf0-4e9a-942c-119d34cbe4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image types are original or \"synth\" from different DNN layers\n",
    "n_layers=2\n",
    "n_image_types = n_layers+1 \n",
    "\n",
    "cue_levels = ['basic', 'super']\n",
    "n_cue_levels = len(cue_levels); # basic or superordinate\n",
    "\n",
    "\n",
    "# creating up to three sessions. \n",
    "# each session is counter-balanced for everything within session.\n",
    "# images are all unique, across all sessions for a given participant.\n",
    "n_sessions = 3;\n",
    "\n",
    "# number of times each condition is \"repeated\"\n",
    "# the images are different each time\n",
    "# this is the min N trials in each condition\n",
    "n_repeats_total = 6;\n",
    "assert(np.mod(n_repeats_total, n_sessions)==0)\n",
    "n_repeats_per_session = int(n_repeats_total/n_sessions)\n",
    "\n",
    "n_trials_total = n_categ_use * n_concepts_use * n_image_types * n_cue_levels * n_repeats_total\n",
    "\n",
    "# how many unique exemplars will we need for all sessions?\n",
    "n_ex_use = n_image_types * n_cue_levels * n_repeats_total\n",
    "\n",
    "# this is per session\n",
    "# n_trials_per_concept = n_image_types * n_cue_levels\n",
    "# assert(n_trials_per_concept==n_ex_use)\n",
    "\n",
    "n_trials_per_session = int(n_trials_total / n_sessions)\n",
    "\n",
    "# this is all per session\n",
    "n_runs = 12;\n",
    "assert(np.mod(n_trials_per_session, n_runs)==0)\n",
    "n_trials_per_run = int(n_trials_per_session/n_runs);\n",
    "\n",
    "# each run will have 4 mini-blocks of 12 trials each\n",
    "n_trials_mini = 12\n",
    "\n",
    "assert(np.mod(n_trials_per_run, n_trials_mini)==0)\n",
    "n_mini_per_run = int(n_trials_per_run/n_trials_mini)\n",
    "\n",
    "n_mini_total = n_mini_per_run * n_runs\n",
    "\n",
    "# for each superordinate category, how many mini-blocks will we do for that category?\n",
    "# this is just for the \"fine\"/basic-level task.\n",
    "# for this to work, we need the total number of miniblocks (div by 2, because just the fine task)\n",
    "# to be divisible by number of superord categories.\n",
    "assert(np.mod(n_mini_total/2, n_categ_use)==0)\n",
    "n_mini_per_categ = n_mini_total / n_cue_levels / n_categ_use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "65c41077-5149-4770-96a3-12e9d341baab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_mini_per_categ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "294ce436-b8c3-455a-9627-6dac78c78e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 * 12 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c584ce26-8643-4d91-ac26-9e3dfff23545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['insect', 'mammal', 'vegetable', 'fruit', 'tool', 'musical_instrument', 'furniture', 'vehicle']\n"
     ]
    }
   ],
   "source": [
    "# n_trials_per_categ = n_trials_per_run # this just happens to work out this way\n",
    "# n_mini_per_categ = int(n_trials_per_categ / n_trials_mini)\n",
    "\n",
    "np.random.seed(rndseed)\n",
    "\n",
    "categ_use = categ_sets[0]\n",
    "categ_use = [c.replace(' ', '_') for c in categ_use]\n",
    "print(categ_use)\n",
    "concepts_use = concept_sets[0]\n",
    "\n",
    "# make 100 different randomized orders for this same image set\n",
    "n_random_orders=2;\n",
    "# n_random_orders=100;\n",
    "\n",
    "# this will be a list over all randomized orders\n",
    "trial_info_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7502e372-6240-4eb4-ac53-5afcca417da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trials_per_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d4bd0f08-116a-4231-a0b1-ca996347a5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['beetle', 'bee', 'butterfly', 'grasshopper', 'caterpillar', 'ant'],\n",
       " ['dog', 'lion', 'horse', 'squirrel', 'elephant', 'cow'],\n",
       " ['pea', 'corn', 'pumpkin', 'onion', 'cabbage', 'lettuce'],\n",
       " ['grape', 'cherry', 'raspberry', 'apple', 'pear', 'banana'],\n",
       " ['pencil', 'knife', 'axe', 'broom', 'hammer', 'shovel'],\n",
       " ['bell', 'guitar', 'piano', 'drum', 'violin', 'trumpet'],\n",
       " ['table', 'bench', 'couch', 'television', 'bed', 'chair'],\n",
       " ['ship', 'train', 'airplane', 'truck', 'car', 'bus']]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3226a2df-6a84-441c-b070-67e0d2a8f36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# for rand in range(n_random_orders):\n",
    "rand = 0\n",
    "\n",
    "# this will be a list for this random order, all sessions\n",
    "trial_info_allsess = []\n",
    "\n",
    "# this is a coinflip that will be used to pick which task to start with\n",
    "odd_even = int(np.random.normal(0,1,1)>0)\n",
    "print(odd_even)\n",
    "\n",
    "ex_each_sess = dict()\n",
    "for bname in basic_names:\n",
    "    # this is the order of the exemplars to use, sorted by synth losses\n",
    "    # picking the best ones to use for the experiment \n",
    "    order = l[bname]['order'][0:n_ex_use]\n",
    "    # each of these exemplars can be used exactly once in whole experiment \n",
    "    # (across all image types).\n",
    "    # going to randomize how these exemplars are assigned to sessions. \n",
    "    rndorder = order[np.random.permutation(len(order))]\n",
    "    ex_each_sess[bname] = np.reshape(rndorder, [int(n_ex_use/n_sessions), n_sessions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dc18cfe2-0b50-4196-b6e6-c0a5533b5c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making rand order 0, session 0\n"
     ]
    }
   ],
   "source": [
    "sess = 0;\n",
    "\n",
    "# for sess in range(n_sessions):\n",
    "\n",
    "print('making rand order %d, session %d'%(rand, sess))\n",
    "    \n",
    "\n",
    "trial_info = pd.DataFrame({'trial_num_overall': np.zeros((n_trials_per_session,)), \n",
    "               'trial_in_run': np.zeros((n_trials_per_session,)), \n",
    "               'trial_in_miniblock': np.zeros((n_trials_per_session,)), \n",
    "                'run_number': np.zeros((n_trials_per_session,)), \n",
    "                'miniblock_number_overall': np.zeros((n_trials_per_session,)), \n",
    "                'miniblock_number_in_run': np.zeros((n_trials_per_session,)), \n",
    "                'session_number': np.zeros((n_trials_per_session,)), \n",
    "                'image_set_num': np.zeros((n_trials_per_session,)), \n",
    "                'random_order_number': np.zeros((n_trials_per_session,)), \n",
    "               'categ_ind': np.zeros((n_trials_per_session,)),\n",
    "              'concept_ind': np.zeros((n_trials_per_session,)),\n",
    "              'super_name': np.zeros((n_trials_per_session,)),\n",
    "              'basic_name': np.zeros((n_trials_per_session,)),\n",
    "              'ex_num': np.zeros((n_trials_per_session,)),\n",
    "              'ex_num_actual': np.zeros((n_trials_per_session,)),\n",
    "              'image_type_num': np.zeros((n_trials_per_session,)),\n",
    "              'image_type': np.zeros((n_trials_per_session,)),\n",
    "              'image_name': np.zeros((n_trials_per_session,)),\n",
    "              'cue_level_num': np.zeros((n_trials_per_session,)),\n",
    "              'cue_level': np.zeros((n_trials_per_session,)),\n",
    "              'cue_name': np.zeros((n_trials_per_session,)),\n",
    "              'distractor_name': np.zeros((n_trials_per_session,)),\n",
    "              'left_name': np.zeros((n_trials_per_session,)),\n",
    "              'right_name': np.zeros((n_trials_per_session,)),\n",
    "              'correct_resp': np.zeros((n_trials_per_session,)), \n",
    "              'repeat_num': np.zeros((n_trials_per_session,)), \n",
    "\n",
    "              })\n",
    "\n",
    "# image_type_names = ['orig', 'pool1','pool2','pool3','pool4']\n",
    "image_type_names = ['orig', 'pool1','pool3']\n",
    "\n",
    "tt=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "72a3c4ef-ba53-4c80-9669-26748a4a7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proc trial 0 of 576\n",
      "proc trial 100 of 576\n",
      "proc trial 200 of 576\n",
      "proc trial 300 of 576\n",
      "proc trial 400 of 576\n",
      "proc trial 500 of 576\n"
     ]
    }
   ],
   "source": [
    "for ca in range(n_categ_use):\n",
    "\n",
    "    for co in range(n_concepts_use):\n",
    "\n",
    "        bname = concepts_use[ca][co]\n",
    "        \n",
    "        ex = -1\n",
    "\n",
    "        # this is the set of exemplars assigned to this session.\n",
    "        # they will be randomly assigned to trial types\n",
    "        # for example ex01 might be used for intact or pool4, but never both\n",
    "        ex_use_list = ex_each_sess[bname][:,sess]\n",
    "       \n",
    "        for typ in range(n_image_types):\n",
    "            for cue in range(n_cue_levels):\n",
    "\n",
    "                for rr in range(n_repeats_per_session):\n",
    "    \n",
    "                    tt+=1\n",
    "                    if np.mod(tt,100)==0:\n",
    "                        print('proc trial %d of %d'%(tt, n_trials_per_session))\n",
    "    \n",
    "                    trial_info['trial_num_overall'].iloc[tt] = tt\n",
    "                    trial_info['categ_ind'].iloc[tt] = ca\n",
    "                    trial_info['concept_ind'].iloc[tt] = co\n",
    "                    trial_info['super_name'].iloc[tt] = categ_use[ca]\n",
    "                    trial_info['basic_name'].iloc[tt] = concepts_use[ca][co].replace(' ', '_')\n",
    "    \n",
    "                    trial_info['image_type_num'].iloc[tt] = typ\n",
    "                    trial_info['image_type'].iloc[tt] = image_type_names[typ]\n",
    "                    trial_info['cue_level_num'].iloc[tt] = cue\n",
    "                    trial_info['cue_level'].iloc[tt] = cue_levels[cue]\n",
    "    \n",
    "                    trial_info['image_set_num'].iloc[tt] = 0\n",
    "                    trial_info['random_order_number'].iloc[tt] = rand\n",
    "                    trial_info['session_number'].iloc[tt] = sess\n",
    "                    trial_info['repeat_num'].iloc[tt] = rr\n",
    "                    \n",
    "                    ex += 1\n",
    "                    # this is the exemplar index within the experiment\n",
    "                    trial_info['ex_num'].iloc[tt] = ex\n",
    "    \n",
    "                    # this is the actual number of the exemplar, 0-40\n",
    "                    ex_num_actual = ex_use_list[ex]\n",
    "                    trial_info['ex_num_actual'].iloc[tt] = ex_num_actual\n",
    "    \n",
    "                    ex_name = 'ex%02d'%(ex_num_actual)\n",
    "                    \n",
    "                    if image_type_names[typ]=='orig':\n",
    "    \n",
    "                        trial_info['image_name'].iloc[tt] = os.path.join(bname, ex_name, 'orig.png')\n",
    "    \n",
    "                    else:\n",
    "    \n",
    "                        trial_info['image_name'].iloc[tt] = os.path.join(bname, ex_name,\n",
    "                                                                         'scramble_upto_%s.png'%\\\n",
    "                                                                         (image_type_names[typ]))\n",
    "                       \n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ee3da94b-ee45-4285-a08c-97ad658ec300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# figure out the sequence of which task happens when\n",
    "\n",
    "# this value is always alternating across sessions\n",
    "odd_even += 1\n",
    "odd_even = np.mod(odd_even,2)\n",
    "print(odd_even)\n",
    "\n",
    "miniblock_list = np.arange(n_mini_total)\n",
    "miniblock_run = np.repeat(np.arange(n_runs), n_mini_per_run)\n",
    "\n",
    "# miniblock tasks will always alternate, within a run\n",
    "miniblock_task = np.roll(np.tile(np.arange(n_cue_levels), [int(n_mini_total/2),]), odd_even)\n",
    "\n",
    "# flip the ordering of task within the \"odd\" runs\n",
    "# so that every other run starts with coarse/fine miniblock\n",
    "for rr in np.arange(1, n_runs, 2):\n",
    "    miniblock_task[miniblock_run==rr] = np.flipud(miniblock_task[miniblock_run==rr])\n",
    "\n",
    "# decide which super-category is being tested on each run of the basic task\n",
    "# for the super task, this isn't relevant\n",
    "miniblock_supcat = np.zeros_like(miniblock_list)\n",
    "miniblock_supcat[miniblock_task==1] = -1\n",
    "\n",
    "# want to find a way of assigning super-categories to miniblocks\n",
    "# so that we don't have the same super-category twice in a run\n",
    "# use brute force randomization to find good sequence\n",
    "good_seq = False\n",
    "max_iter = 100\n",
    "ii = 0;\n",
    "while (not good_seq) and (ii < max_iter):\n",
    "\n",
    "    supcat_seq = np.repeat(np.arange(n_categ_use), n_mini_per_categ)\n",
    "    supcat_seq = supcat_seq[np.random.permutation(len(supcat_seq))]\n",
    "    miniblock_supcat[miniblock_task==0] = supcat_seq\n",
    "\n",
    "    un_cats = [np.unique(miniblock_supcat[(miniblock_task==0) & (miniblock_run==rr)]) \\\n",
    "               for rr in range(n_runs)]\n",
    "    good_seq = np.all([len(u)==2 for u in un_cats])\n",
    "\n",
    "    ii+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a6b3f252-0a79-41c6-8ddf-61b9e5749ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# now group the trials into runs based on which task is being done\n",
    "            \n",
    "# first basic-level tasks, within each superordinate   \n",
    "for si, sname in enumerate(categ_use):\n",
    "\n",
    "    for typ in range(n_image_types):\n",
    "\n",
    "        for rr in range(n_repeats_per_session):\n",
    "        \n",
    "    \n",
    "            trial_inds = np.array((trial_info['super_name']==sname) & \\\n",
    "                                  (trial_info['cue_level']=='basic') & \\\n",
    "                                  (trial_info['image_type_num']==typ) & \\\n",
    "                                  (trial_info['repeat_num']==rr))\n",
    "    \n",
    "            # name of actual basic-level category\n",
    "            cue_names_actual = np.array(trial_info['basic_name'].iloc[trial_inds])\n",
    "    \n",
    "            # now assign the \"distractor\" names by shuffling real names\n",
    "            distract_names = expt_utils.shuffle_nosame(cue_names_actual)\n",
    "    \n",
    "            trial_info['cue_name'].iloc[trial_inds] =  cue_names_actual\n",
    "            trial_info['distractor_name'].iloc[trial_inds] = distract_names\n",
    "    \n",
    "            # randomly assign whether left or right side is the actual cue name \n",
    "            cue_on_left = np.mod(np.random.permutation(len(cue_names_actual)),2)==0\n",
    "            left_name = copy.deepcopy(cue_names_actual)\n",
    "            right_name = copy.deepcopy(distract_names)\n",
    "            # switch half of them\n",
    "            left_name[~cue_on_left] = distract_names[~cue_on_left]\n",
    "            right_name[~cue_on_left] = cue_names_actual[~cue_on_left]\n",
    "    \n",
    "            # correct resp: 1 for left, 2 for right\n",
    "            correct_resp = np.ones_like(cue_on_left).astype(int)\n",
    "            correct_resp[~cue_on_left] = 2\n",
    "    \n",
    "            trial_info['left_name'].iloc[trial_inds] = left_name\n",
    "            trial_info['right_name'].iloc[trial_inds] = right_name\n",
    "    \n",
    "            trial_info['correct_resp'].iloc[trial_inds] = correct_resp\n",
    "    \n",
    "\n",
    "    # now grab the trials for all image types, within this superordinate categ\n",
    "    trial_inds = np.array((trial_info['super_name']==sname) & \\\n",
    "                              (trial_info['cue_level']=='basic'))\n",
    "\n",
    "    # break all these into equal sized \"mini-blocks\" randomly\n",
    "    # assigning to the block numbers that we already decided on previously\n",
    "    miniblock_inds_use = np.repeat(miniblock_list[miniblock_supcat==si], n_trials_mini)\n",
    "    run_inds_use = np.repeat(miniblock_run[miniblock_supcat==si], n_trials_mini)\n",
    "\n",
    "    rand_order = np.random.permutation(len(miniblock_inds_use))\n",
    "    miniblock_inds_use = miniblock_inds_use[rand_order]\n",
    "    run_inds_use = run_inds_use[rand_order]\n",
    "\n",
    "    # print(miniblock_inds_use )\n",
    "    trial_info['run_number'].iloc[trial_inds] = run_inds_use\n",
    "    trial_info['miniblock_number_overall'].iloc[trial_inds] = miniblock_inds_use\n",
    "    trial_info['miniblock_number_in_run'].iloc[trial_inds] = np.mod(miniblock_inds_use, n_mini_per_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "43311eb3-e69b-48ef-8d8a-ad57e31d04f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['airplane', 'bus', 'car', 'ship', 'train', 'truck'], dtype=object),\n",
       " array([1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(cue_names_actual, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4620c991-76c2-42b4-a60a-59ad4805b69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now organizing the superordinate task runs\n",
    "# looping over image types, things will be shuffled within image type\n",
    "for typ in range(n_image_types):\n",
    "\n",
    "    for rr in range(n_repeats_per_session):\n",
    "            \n",
    "        trial_inds = np.array((trial_info['cue_level']=='super') & \\\n",
    "                              (trial_info['image_type_num']==typ) & \\\n",
    "                              (trial_info['repeat_num']==rr))\n",
    "                              \n",
    "    \n",
    "        # print(np.sum(trial_inds))\n",
    "    \n",
    "        # actual cue names (superordinate)\n",
    "        cue_names_actual = np.array(trial_info['super_name'].iloc[trial_inds])\n",
    "    \n",
    "        # creating the list of \"distractor\" names that are pseudorandom\n",
    "        # this works when there are exactly 6 trials per each of 8 superordinate category\n",
    "        # first we list all the categories that can be used as distractors (this is 7 per category)\n",
    "        distract_names = [np.array(categ_use)[np.array(categ_use)!=categ] for categ in categ_use]\n",
    "        # then we're going to remove one of these, but in a systematic way so it's balanced across \n",
    "        # whole experiment. will have 6 left for distractors\n",
    "        extras = expt_utils.shuffle_nosame(np.array(categ_use))\n",
    "        distract_names = [d[d!=e] for [d, e] in zip(distract_names, extras)]\n",
    "        # now shuffle the order...\n",
    "        distract_names = [d[np.random.permutation(len(d))] for d in distract_names]\n",
    "        \n",
    "        distract_names = np.concatenate(distract_names, axis=0)\n",
    "    \n",
    "        # check they meet all the criteria\n",
    "        un, counts = np.unique(distract_names, return_counts=True)\n",
    "        assert(np.all(counts==counts[0]))\n",
    "        assert not np.any(distract_names==cue_names_actual)\n",
    "    \n",
    "        trial_info['cue_name'].iloc[trial_inds] =  cue_names_actual\n",
    "        trial_info['distractor_name'].iloc[trial_inds] = distract_names\n",
    "    \n",
    "    \n",
    "        # randomly assign whether left or right side is the actual cue name \n",
    "        n_each = [np.sum(cue_names_actual==categ) for categ in categ_use]\n",
    "        cue_on_left = np.concatenate([np.mod(np.random.permutation(n),2)==0 for n in n_each], \\\n",
    "                                     axis=0)\n",
    "        left_name = copy.deepcopy(cue_names_actual)\n",
    "        right_name = copy.deepcopy(distract_names)\n",
    "        # switch half of them\n",
    "        left_name[~cue_on_left] = distract_names[~cue_on_left]\n",
    "        right_name[~cue_on_left] = cue_names_actual[~cue_on_left]\n",
    "    \n",
    "        # correct resp: 1 for left, 2 for right\n",
    "        correct_resp = np.ones_like(cue_on_left).astype(int)\n",
    "        correct_resp[~cue_on_left] = 2\n",
    "    \n",
    "        trial_info['left_name'].iloc[trial_inds] = left_name\n",
    "        trial_info['right_name'].iloc[trial_inds] = right_name\n",
    "    \n",
    "        trial_info['correct_resp'].iloc[trial_inds] = correct_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a229b780-4cb2-4516-b46b-449a106008f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking trial info\n"
     ]
    }
   ],
   "source": [
    "# now grab all the trials in superordinate task, all image types\n",
    "trial_inds = np.array(trial_info['cue_level']=='super')\n",
    "\n",
    "# break all these into equal sized \"mini-blocks\" randomly\n",
    "# assigning to the block numbers that we already decided on previously\n",
    "miniblock_inds_use = np.repeat(miniblock_list[miniblock_task==1], n_trials_mini)\n",
    "run_inds_use = np.repeat(miniblock_run[miniblock_task==1], n_trials_mini)\n",
    "\n",
    "rand_order = np.random.permutation(len(miniblock_inds_use))\n",
    "miniblock_inds_use = miniblock_inds_use[rand_order]\n",
    "run_inds_use = run_inds_use[rand_order]\n",
    "\n",
    "# print(miniblock_inds_use)\n",
    "\n",
    "trial_info['run_number'].iloc[trial_inds] = run_inds_use\n",
    "trial_info['miniblock_number_overall'].iloc[trial_inds] = miniblock_inds_use\n",
    "trial_info['miniblock_number_in_run'].iloc[trial_inds] = np.mod(miniblock_inds_use, n_mini_per_run)\n",
    "\n",
    "\n",
    "# organize the trials by mini-block number\n",
    "trial_info.sort_values(by='miniblock_number_overall', inplace=True)\n",
    "\n",
    "# now shuffle within each mini-block\n",
    "for mb in np.unique(trial_info['miniblock_number_overall']):\n",
    "\n",
    "    inds = np.where(np.array(trial_info['miniblock_number_overall']==mb))[0] \n",
    "    shuff_order = np.random.permutation(len(inds))\n",
    "    trial_info.iloc[inds] = trial_info.iloc[inds[shuff_order]]\n",
    "\n",
    "# assign trial numbers \n",
    "trial_info['trial_in_miniblock'] = np.tile(np.arange(n_trials_mini), [n_mini_total,])\n",
    "trial_info['trial_in_run'] = np.tile(np.arange(n_trials_per_run), [n_runs,])\n",
    "trial_info['trial_num_overall'] = np.arange(n_trials_per_session)\n",
    "\n",
    "trial_info.set_index(np.arange(n_trials_per_session))\n",
    "\n",
    "\n",
    "# double check everything\n",
    "print('checking trial info')\n",
    "check_trial_info(trial_info, concepts_use, categ_use)\n",
    "\n",
    "trial_info_allsess += [trial_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d9f279c1-e72f-4d96-a4ee-7f78f82df439",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_trial_info(ti, concepts_use, categ_use):\n",
    "\n",
    "    # double checking all the trial attributes\n",
    "    \n",
    "    \n",
    "    # check that we assigned the \"correct response\" correctly\n",
    "    # 1 is left, 2 is right\n",
    "    inds_check = np.array(ti['correct_resp']==1)\n",
    "    assert(np.all(ti['cue_name'][inds_check]==ti['left_name'][inds_check]))\n",
    "    inds_check = np.array(ti['correct_resp']==2)\n",
    "    assert(np.all(ti['cue_name'][inds_check]==ti['right_name'][inds_check]))\n",
    "\n",
    "    # cue and distractor name always different\n",
    "    assert(not np.any(ti['cue_name']==ti['distractor_name']))\n",
    "\n",
    "    # check that basic and super task are assigned correctly\n",
    "    inds_check = np.array(ti['cue_level']=='basic')\n",
    "    assert(np.all(np.isin(np.array(ti['cue_name'].iloc[inds_check]), concepts_use)))\n",
    "    assert(np.all(np.isin(np.array(ti['distractor_name'].iloc[inds_check]), concepts_use)))\n",
    "\n",
    "    # for each basic block checking that the cue and distractor names are all part of a single superord categ\n",
    "    for mb in np.unique(ti['miniblock_number_overall'].iloc[inds_check]):\n",
    "        inds_check_mb = inds_check & (np.array(ti['miniblock_number_overall']==mb))\n",
    "        sname = np.array(ti['super_name'].iloc[inds_check_mb])\n",
    "        assert(np.all(sname==sname[0]))\n",
    "        sind = np.where(np.array(categ_use)==sname[0])[0][0]\n",
    "        assert(np.all(np.isin(np.array(ti['distractor_name'].iloc[inds_check_mb]), concepts_use[sind])))\n",
    "        assert(np.all(np.isin(np.array(ti['cue_name'].iloc[inds_check_mb]), concepts_use[sind])))\n",
    "\n",
    "    # check superordinate names \n",
    "    inds_check = np.array(ti['cue_level']=='super')\n",
    "    assert(np.all(np.isin(np.array(ti['cue_name'].iloc[inds_check]), categ_use)))\n",
    "    assert(np.all(np.isin(np.array(ti['distractor_name'].iloc[inds_check]), categ_use)))\n",
    "\n",
    "    # check to make sure individual attributes are distributed evenly across trials \n",
    "    n_trials_per_session = ti.shape[0]\n",
    "\n",
    "    attr_check_even = ['super_name', 'basic_name', 'ex_num', 'image_type_num', \\\n",
    "                       'correct_resp', 'cue_level', 'run_number', \\\n",
    "                       'miniblock_number_overall', 'miniblock_number_in_run']\n",
    "    for attr in attr_check_even:\n",
    "\n",
    "        # should be an equal number of each thing \n",
    "        un, counts = np.unique(ti[attr], return_counts=True)\n",
    "        # print(un, counts)\n",
    "        assert(np.all(counts==n_trials_per_session/len(un)))\n",
    "\n",
    "    \n",
    "    # check the counterbalancing over multiple attributes\n",
    "\n",
    "    # there should be an equal number of trials in each of the combinations of these \n",
    "    # different attribute \"levels\". for example each combination of category/image type. \n",
    "\n",
    "    attr_balanced = [ti['categ_ind'], ti['concept_ind'], ti['image_type_num'], ti['cue_level']]\n",
    "    attr_balanced_inds = np.array([np.unique(attr, return_inverse=True)[1] for attr in attr_balanced]).T\n",
    "\n",
    "    n_levels_each = [len(np.unique(attr)) for attr in attr_balanced]\n",
    "    n_combs_expected = np.prod(n_levels_each)\n",
    "    n_repeats_expected = n_trials_per_session/n_combs_expected\n",
    "\n",
    "    un_rows, counts = np.unique(attr_balanced_inds,axis=0, return_counts=True)\n",
    "\n",
    "    assert(un_rows.shape[0]==n_combs_expected)\n",
    "    assert(np.all(counts==n_repeats_expected))\n",
    "\n",
    "    \n",
    "    \n",
    "    # check evenness of stuff for super task only\n",
    "\n",
    "    inds_check = np.array(ti['cue_level']=='super')\n",
    "    n_trials_per_session = np.sum(inds_check)\n",
    "\n",
    "    attr_check_even = ['super_name', 'cue_name', 'image_type', 'distractor_name', 'correct_resp']\n",
    "\n",
    "    for attr in attr_check_even:\n",
    "\n",
    "        # should be an equal number of each thing \n",
    "        un, counts = np.unique(ti[attr].iloc[inds_check], return_counts=True)\n",
    "        # print(un, counts)\n",
    "        assert(np.all(counts==n_trials_per_session/len(un)))\n",
    "\n",
    "\n",
    "\n",
    "    # check evenness of stuff for basic task only\n",
    "\n",
    "    inds_check = np.array(ti['cue_level']=='basic')\n",
    "    n_trials_per_session = np.sum(inds_check)\n",
    "\n",
    "    attr_check_even = ['basic_name', 'cue_name', 'image_type', 'distractor_name', 'correct_resp']\n",
    "\n",
    "    for attr in attr_check_even:\n",
    "\n",
    "        # should be an equal number of each thing \n",
    "        un, counts = np.unique(ti[attr].iloc[inds_check], return_counts=True)\n",
    "        # print(un, counts)\n",
    "        assert(np.all(counts==n_trials_per_session/len(un)))\n",
    "\n",
    "    # making sure that for the different superordinate tasks, \n",
    "    # the miniblocks all fall on different runs\n",
    "    for si, sname in enumerate(categ_use):\n",
    "        \n",
    "        inds = (ti['cue_level']=='basic') & (ti['super_name']==sname)\n",
    "        assert(len(np.unique(ti['run_number'][inds])) == n_mini_per_categ)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e473bb-8ba0-4282-b8f5-9eba98663baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # concatenating the trials for all sessions together\n",
    "    trial_info_allsess = pd.concat(trial_info_allsess)\n",
    "\n",
    "    # fix the indexing\n",
    "    trial_info_allsess.set_index(np.arange(n_trials_per_session * n_sessions))\n",
    "\n",
    "    # making a variable that tracks all runs across all sessions\n",
    "    trial_info_allsess['run_number_overall'] = trial_info_allsess['run_number'] + trial_info_allsess['session_number']*n_runs\n",
    "\n",
    "    # checking that all exemplars are unique across whole expt\n",
    "    \n",
    "    names = trial_info_allsess['image_name']\n",
    "    bnames = [n.split('/')[0] for n in names]\n",
    "    enames = [n.split('/')[1] for n in names]\n",
    "    \n",
    "    un = np.unique(np.array([bnames, enames]), axis=1)\n",
    "    assert(un.shape[1]==len(bnames))\n",
    "\n",
    "\n",
    "    # save everything to a single CSV file\n",
    "    # this has all sessions included\n",
    "    expt_design_folder = os.path.join(project_root, 'expt_design', expt_name)\n",
    "    if not os.path.exists(expt_design_folder):\n",
    "        os.makedirs(expt_design_folder)\n",
    "    trialinfo_filename1 =  os.path.join(expt_design_folder, 'trial_info_randorder%d.csv'%(rand))\n",
    "    print('saving to %s'%trialinfo_filename1)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    trial_info_allsess.to_csv(trialinfo_filename1, index=False)\n",
    "\n",
    "    # putting into bigger list here\n",
    "    trial_info_list += [trial_info_allsess]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
