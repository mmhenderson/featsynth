{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3036e873-1ed9-46f1-b87d-7147f4d7e5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn import decomposition\n",
    "import pandas as pd\n",
    "import torch\n",
    "import PIL\n",
    "\n",
    "project_root = '/user_data/mmhender/featsynth/'\n",
    "texture_synth_root = os.path.join(project_root, 'texture_synthesis')\n",
    "\n",
    "# these are in the 'texture_synthesis' folder\n",
    "sys.path.append(os.path.join(texture_synth_root, 'code'))\n",
    "import utilities\n",
    "import model_spatial\n",
    "\n",
    "# from image_analysis import extract_resnet_features\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9acf3f71-5afc-47f9-947d-63c7f2512e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_set_name = 'images_ecoset64'\n",
    "folder_images = os.path.join(project_root, 'features','raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c280193-92aa-47e6-a33c-4ccc8f798c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_set_name = 'images_things200'\n",
    "folder_images = os.path.join(project_root, 'features','raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b39a2bd9-34a4-4fd6-9102-27efbac4e033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicating list from /user_data/mmhender/featsynth/features/raw/images_things200_list.csv to /user_data/mmhender/featsynth/features/raw/images_things200_grayscale_list.csv\n"
     ]
    }
   ],
   "source": [
    "list_orig = os.path.join(folder_images, '%s_list.csv'%(image_set_name))\n",
    "list_new = os.path.join(folder_images, '%s_grayscale_list.csv'%(image_set_name))\n",
    "print('duplicating list from %s to %s'%(list_orig, list_new))\n",
    "d = pd.read_csv(list_orig)\n",
    "d.to_csv(list_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f270921e-0b18-48db-8fcd-43f54d1683f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_set_name = 'images_ecoset'\n",
    "layer_process = 'pool1'\n",
    "debug = False\n",
    "n_per_categ = 100\n",
    "n_cv = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a5422a7-dfdd-4cbc-9578-faeb7d9874a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug=False\n",
      "['pool1']\n",
      "/user_data/mmhender/featsynth/features/gram_matrices/images_ecoset_gram_matrices_pool1_pca.npy\n",
      "will save to /user_data/mmhender/featsynth/features/gram_matrices/categ_discrim/categ_discrim_allbasic_images_ecoset_pool1_100percateg.npy\n",
      "there are 500 images for beetle, choosing 100\n",
      "there are 500 images for bee, choosing 100\n",
      "there are 500 images for butterfly, choosing 100\n",
      "there are 500 images for grasshopper, choosing 100\n",
      "there are 500 images for caterpillar, choosing 100\n",
      "there are 500 images for ant, choosing 100\n",
      "there are 500 images for moth, choosing 100\n",
      "there are 500 images for mosquito, choosing 100\n",
      "there are 500 images for pea, choosing 100\n",
      "there are 500 images for corn, choosing 100\n",
      "there are 500 images for pumpkin, choosing 100\n",
      "there are 500 images for onion, choosing 100\n",
      "there are 500 images for cabbage, choosing 100\n",
      "there are 500 images for lettuce, choosing 100\n",
      "there are 500 images for beet, choosing 100\n",
      "there are 500 images for asparagus, choosing 100\n",
      "there are 500 images for grape, choosing 100\n",
      "there are 500 images for cherry, choosing 100\n",
      "there are 500 images for raspberry, choosing 100\n",
      "there are 500 images for apple, choosing 100\n",
      "there are 500 images for pear, choosing 100\n",
      "there are 500 images for banana, choosing 100\n",
      "there are 500 images for pomegranate, choosing 100\n",
      "there are 500 images for coconut, choosing 100\n",
      "there are 500 images for candy, choosing 100\n",
      "there are 500 images for muffin, choosing 100\n",
      "there are 500 images for pastry, choosing 100\n",
      "there are 500 images for cupcake, choosing 100\n",
      "there are 500 images for cookie, choosing 100\n",
      "there are 500 images for pie, choosing 100\n",
      "there are 500 images for milkshake, choosing 100\n",
      "there are 500 images for brownie, choosing 100\n",
      "there are 500 images for pencil, choosing 100\n",
      "there are 500 images for knife, choosing 100\n",
      "there are 500 images for axe, choosing 100\n",
      "there are 500 images for broom, choosing 100\n",
      "there are 500 images for hammer, choosing 100\n",
      "there are 500 images for shovel, choosing 100\n",
      "there are 500 images for spoon, choosing 100\n",
      "there are 500 images for scissors, choosing 100\n",
      "there are 500 images for bell, choosing 100\n",
      "there are 500 images for guitar, choosing 100\n",
      "there are 500 images for piano, choosing 100\n",
      "there are 500 images for drum, choosing 100\n",
      "there are 500 images for violin, choosing 100\n",
      "there are 500 images for mandolin, choosing 100\n",
      "there are 500 images for clarinet, choosing 100\n",
      "there are 500 images for ukulele, choosing 100\n",
      "there are 500 images for table, choosing 100\n",
      "there are 500 images for bench, choosing 100\n",
      "there are 500 images for couch, choosing 100\n",
      "there are 500 images for television, choosing 100\n",
      "there are 500 images for bed, choosing 100\n",
      "there are 500 images for chair, choosing 100\n",
      "there are 500 images for refrigerator, choosing 100\n",
      "there are 500 images for lamp, choosing 100\n",
      "there are 500 images for ship, choosing 100\n",
      "there are 500 images for train, choosing 100\n",
      "there are 500 images for airplane, choosing 100\n",
      "there are 500 images for truck, choosing 100\n",
      "there are 500 images for car, choosing 100\n",
      "there are 500 images for bus, choosing 100\n",
      "there are 500 images for motorcycle, choosing 100\n",
      "there are 500 images for canoe, choosing 100\n",
      "total ims subsampled for basic-all: 6400\n"
     ]
    }
   ],
   "source": [
    "print('debug=%s'%debug)\n",
    "\n",
    "# load image features\n",
    "feat_path = os.path.join(project_root, 'features', 'gram_matrices')\n",
    "\n",
    "feat_all = []\n",
    "\n",
    "layers_process = [layer_process]\n",
    "print(layers_process)\n",
    "for li in range(len(layers_process)):\n",
    "\n",
    "    feat_file_name = os.path.join(feat_path, \\\n",
    "                                  '%s_gram_matrices_%s_pca.npy'%(image_set_name,\\\n",
    "                                                           layers_process[li]))\n",
    "    print(feat_file_name)\n",
    "    feat = np.load(feat_file_name)\n",
    "\n",
    "    feat_all += [feat]\n",
    "\n",
    "feat_all = np.concatenate(feat_all, axis=1)\n",
    "feat = feat_all\n",
    "feat = scipy.stats.zscore(feat, axis=0)\n",
    "\n",
    "save_dir = os.path.join(feat_path, 'categ_discrim')\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "fn2save = os.path.join(save_dir, 'categ_discrim_allbasic_%s_%s_%dpercateg.npy'%\\\n",
    "                       (image_set_name, layer_process, n_per_categ))\n",
    "print('will save to %s'%fn2save)\n",
    "\n",
    "\n",
    "# load corresponding labels for the images\n",
    "image_list_filename = os.path.join(project_root, 'features','raw', '%s_list.csv'%(image_set_name))\n",
    "labels = pd.read_csv(image_list_filename)\n",
    "n_images = labels.shape[0]\n",
    "\n",
    "# figure out some image/category properties here\n",
    "n_ims_each = np.sum(np.array(labels['basic_name'])==np.array(labels['basic_name'])[0])\n",
    "basic_names = np.array(labels['basic_name'][0::n_ims_each])\n",
    "super_names_long = np.array(labels['super_name'][0::n_ims_each])\n",
    "\n",
    "n_basic = len(basic_names)\n",
    "n_super = len(np.unique(super_names_long))\n",
    "n_basic_each_super  = int(n_basic/n_super)\n",
    "super_names = super_names_long[0::n_basic_each_super]\n",
    "\n",
    "# info about ecoset categories\n",
    "fn = os.path.join(ecoset_info_path, 'categ_use_ecoset.npy')\n",
    "info = np.load(fn, allow_pickle=True).item()\n",
    "\n",
    "super_acc = np.zeros((1,))\n",
    "super_dprime = np.zeros((1,))\n",
    "super_acc_each_supcat = np.zeros((n_super,))\n",
    "super_dprime_each_supcat = np.zeros((n_super,))\n",
    "    \n",
    "    \n",
    "basic_acc = np.zeros((n_super,))\n",
    "basic_dprime = np.zeros((n_super,))\n",
    "basic_acc_each_bascat = np.zeros((n_basic,))\n",
    "basic_dprime_each_bascat = np.zeros((n_basic,))\n",
    "\n",
    "# create a set of images that have the desired number per superord categ\n",
    "ims_use_subsample = np.zeros((n_images,),dtype=bool)\n",
    "\n",
    "# n_per_categ is how many we want total per superordinate categ.\n",
    "# want to divide these evenly across the basics\n",
    "n_per_basic = n_per_categ\n",
    "\n",
    "for bname in basic_names:\n",
    "\n",
    "    inds = np.where((np.array(labels['basic_name'])==bname))[0]\n",
    "    print('there are %d images for %s, choosing %d'%(len(inds), bname, n_per_basic))\n",
    "    inds_use = np.random.choice(inds, n_per_basic, replace=False)\n",
    "\n",
    "    ims_use_subsample[inds_use] = True  \n",
    "\n",
    "print('total ims subsampled for basic-all: %d'%(np.sum(ims_use_subsample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d10c7863-aece-48a8-bd6c-316fdedb7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_acc = np.zeros((1,))\n",
    "super_dprime = np.zeros((1,))\n",
    "super_acc_each_supcat = np.zeros((n_super,))\n",
    "super_dprime_each_supcat = np.zeros((n_super,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43679152-f5d3-414d-b6ad-d3417941baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "947b1a35-5edb-406d-b1da-9d8fb6136f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of f:\n",
      "(6400, 500)\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([640, 640, 640, 640, 640, 640, 640, 640, 640, 640]))\n",
      "cv 0: best C is 0.01000000\n",
      "cv 1: best C is 0.01000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmhender/imstat_env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv 2: best C is 0.01000000\n",
      "cv 3: best C is 0.01000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmhender/imstat_env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv 4: best C is 0.01000000\n",
      "cv 5: best C is 0.01000000\n",
      "cv 6: best C is 0.01000000\n",
      "cv 7: best C is 0.01000000\n",
      "cv 8: best C is 0.01000000\n",
      "cv 9: best C is 0.01000000\n"
     ]
    }
   ],
   "source": [
    "# do basic-all classification\n",
    "inds = ims_use_subsample\n",
    "\n",
    "f = feat[inds,:]\n",
    "\n",
    "print('size of f:')\n",
    "print(f.shape)\n",
    "\n",
    "labs_use = np.array(labels['basic_index'])[inds]\n",
    "\n",
    "sys.stdout.flush()\n",
    "pred_labs = logreg_clf(f, labs_use, cv_labs=None, n_cv=n_cv, debug=debug).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ae17a3b-102c-462c-8aae-0326cc893741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "super acc=0.47, super dprime=1.37\n"
     ]
    }
   ],
   "source": [
    "# mapping the basic-level labels into superordinate categs\n",
    "super_inds_long = np.repeat(np.arange(n_super), n_basic_each_super)\n",
    "                            \n",
    "pred_labs_super = super_inds_long[pred_labs]\n",
    "actual_labs_super = super_inds_long[labs_use]\n",
    "\n",
    "a = np.mean(pred_labs_super==actual_labs_super)\n",
    "super_acc[0] = a\n",
    "d = stats_utils.get_dprime(pred_labs_super, actual_labs_super)\n",
    "super_dprime[0] = d\n",
    "print('super acc=%.2f, super dprime=%.2f'%(a, d))\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25cc569e-87a6-4c2e-a915-829fb15fdede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy for each individual super-category\n",
    "for si in np.unique(actual_labs_super):\n",
    "\n",
    "    # accuracy just for images in this category\n",
    "    inds = actual_labs_super==si\n",
    "    assert(np.sum(inds)==f.shape[0]/n_super)\n",
    "    super_acc_each_supcat[si] = np.mean(pred_labs_super[inds]==actual_labs_super[inds])\n",
    "\n",
    "    # getting d-prime for each category\n",
    "    # this is actually using all trials - but only measuring performance \n",
    "    # based on whether the presence/absence of this categ was correct.\n",
    "    # convert the labels to binary yes/no\n",
    "    pred_tmp = (pred_labs_super==si).astype('int')\n",
    "    labs_tmp = (actual_labs_super==si).astype('int')\n",
    "\n",
    "    super_dprime_each_supcat[si] = stats_utils.get_dprime(pred_tmp, labs_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e44e6079-6335-434b-b924-84ba928180fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3668467530410147"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(super_dprime_each_supcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "faed1bcb-056a-4820-83a4-939ea1709715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47203124999999996"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(super_acc_each_supcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f9a5ca1-4845-4f1a-8eba-c64c91fbdf68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7]),\n",
       " array([738, 790, 735, 889, 679, 773, 831, 965]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(pred_labs_super, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e1ea5df-b446-4972-b08c-4713065e5570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7]),\n",
       " array([800, 800, 800, 800, 800, 800, 800, 800]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(actual_labs_super, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe67e26-9c12-424b-81e5-a3bc69de6f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic acc=0.27, basic dprime=1.62\n"
     ]
    }
   ],
   "source": [
    "assert(not np.any(np.isnan(pred_labs)))\n",
    "a = np.mean(pred_labs==labs_use)\n",
    "basic_acc[0] = a\n",
    "d = stats_utils.get_dprime(pred_labs, labs_use)\n",
    "basic_dprime[0] = d\n",
    "print('basic acc=%.2f, basic dprime=%.2f'%(a, d))\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12c05ba7-35bb-46ab-9696-2993936d219a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]),\n",
       " array([ 71,  82,  95,  89, 101,  88,  80, 132,  91,  88, 102, 106, 102,\n",
       "        110,  88, 103,  93,  78,  81, 100, 114, 100, 104,  65,  77, 106,\n",
       "        125,  99, 124,  96, 123, 139,  78,  83,  83,  93,  85,  82,  87,\n",
       "         88, 117,  92,  98,  96,  98,  79, 104,  89, 122,  84,  90, 114,\n",
       "        119,  86, 149,  67, 150, 111, 144, 117, 108, 104, 115, 116]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(pred_labs, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d02febc0-4606-48ea-8683-fc49315f1b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]),\n",
       " array([100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labs_use, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37388d90-438b-40f8-89ac-e5b7600b0a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy for each individual basic-category\n",
    "for bi in np.unique(labs_use):\n",
    "\n",
    "    # accuracy just for images in this category\n",
    "    inds = labs_use==bi\n",
    "    assert(np.sum(inds)==f.shape[0]/n_basic)\n",
    "    basic_acc_each_bascat[bi] = np.mean(pred_labs[inds]==labs_use[inds])\n",
    "\n",
    "    # getting d-prime for each category\n",
    "    # this is actually using all trials - but only measuring performance \n",
    "    # based on whether the presence/absence of this categ was correct.\n",
    "    # convert the labels to binary yes/no\n",
    "    pred_tmp = (pred_labs==bi).astype('int')\n",
    "    labs_tmp = (labs_use==bi).astype('int')\n",
    "\n",
    "    basic_dprime_each_bascat[bi] = stats_utils.get_dprime(pred_tmp, labs_tmp)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e2288-b9e8-4329-a8d6-99a1a9542868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a36d40ea-17c1-4414-a0c5-5bb181d46b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07, 0.19, 0.36, 0.11, 0.14, 0.18, 0.08, 0.39, 0.34, 0.43, 0.42,\n",
       "       0.33, 0.34, 0.53, 0.15, 0.27, 0.28, 0.35, 0.38, 0.27, 0.38, 0.38,\n",
       "       0.32, 0.42, 0.26, 0.33, 0.2 , 0.28, 0.28, 0.13, 0.37, 0.47, 0.12,\n",
       "       0.09, 0.05, 0.14, 0.12, 0.13, 0.14, 0.1 , 0.25, 0.14, 0.38, 0.18,\n",
       "       0.4 , 0.23, 0.29, 0.12, 0.25, 0.15, 0.16, 0.47, 0.17, 0.14, 0.54,\n",
       "       0.14, 0.64, 0.41, 0.53, 0.27, 0.24, 0.48, 0.34, 0.31])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_acc_each_bascat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "848dbb46-b5bd-4150-bbee-8e35504b8913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27421874999999996"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(basic_acc_each_bascat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce1154a7-dfea-40f4-902c-6d121135136d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84464207, 1.44845158, 1.99239963, 1.0185689 , 1.12233604,\n",
       "       1.37118286, 0.87074247, 1.89710177, 1.95120041, 2.2736235 ,\n",
       "       2.14270423, 1.83063073, 1.88508885, 2.4389334 , 1.23411051,\n",
       "       1.6422881 , 1.73175689, 2.08100316, 2.16084284, 1.6577309 ,\n",
       "       1.9496203 , 2.02686439, 1.80811523, 2.48087338, 1.76124782,\n",
       "       1.83063073, 1.286424  , 1.69830663, 1.58100423, 1.09463478,\n",
       "       1.87532521, 2.10542019, 1.13385466, 0.92458105, 0.60024339,\n",
       "       1.15985872, 1.0955571 , 1.16562414, 1.19022455, 0.96354546,\n",
       "       1.5062003 , 1.16477768, 2.03911692, 1.32973193, 2.10386557,\n",
       "       1.63136745, 1.70680427, 1.07508412, 1.4852393 , 1.25558188,\n",
       "       1.2708782 , 2.22789016, 1.18551084, 1.19549469, 2.26843315,\n",
       "       1.3101818 , 2.56563735, 2.05900297, 2.26026929, 1.57653676,\n",
       "       1.51006022, 2.32006071, 1.8180366 , 1.715897  ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_dprime_each_bascat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0246ae04-8013-4cf6-9c06-fb3946a389a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6235774057067438"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(basic_dprime_each_bascat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cb3c53-d4db-4e55-b911-e53fec750bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_dprime_each_bascat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba549f11-d31a-44c6-b268-1cda7c8857f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def logreg_clf(feat, labs, cv_labs=None, n_cv = 10, debug=False):\n",
    "\n",
    "    \n",
    "    if cv_labs is None:\n",
    "        # making random cross-validation labels\n",
    "        # balance classes as closely as possible\n",
    "        cv_labs = np.zeros_like(labs)\n",
    "        unvals = np.unique(labs)\n",
    "        for uu in unvals:\n",
    "            inds = np.where(labs==uu)[0]\n",
    "            cv_tmp = np.tile(np.arange(n_cv), [int(np.ceil(len(inds)/n_cv)),])\n",
    "            cv_tmp = cv_tmp[np.random.permutation(len(cv_tmp))][0:len(inds)]\n",
    "            cv_labs[inds] = cv_tmp\n",
    "    \n",
    "    pred_labs = np.full(fill_value=np.nan, shape=cv_labs.shape)\n",
    "    \n",
    "    print(np.unique(cv_labs, return_counts=True))\n",
    "    \n",
    "    for cvi, cv in enumerate(np.unique(cv_labs)):\n",
    "\n",
    "        if debug and cvi>1:\n",
    "            continue\n",
    "            \n",
    "        trninds = cv_labs!=cv\n",
    "        tstinds = cv_labs==cv\n",
    "\n",
    "        cs = np.logspace(-10, 0, 16)\n",
    "        try:\n",
    "            clf = sklearn.linear_model.LogisticRegressionCV(multi_class='multinomial', \\\n",
    "                                                          Cs = cs, fit_intercept=True, \\\n",
    "                                                          penalty = 'l2', \\\n",
    "                                                          refit=True, \\\n",
    "                                                          max_iter=10000, \\\n",
    "                                                         )\n",
    "            clf.fit(feat[trninds,:], labs[trninds])\n",
    "            print('cv %d: best C is %.8f'%(cvi, clf.C_[0]))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            p = clf.predict(feat[tstinds,:])\n",
    "\n",
    "            pred_labs[tstinds] = p\n",
    "            \n",
    "        except:\n",
    "            print('WARNING: problem with classifer, returning nans')\n",
    "            pred_labs[tstinds] = np.nan\n",
    "            \n",
    "    return pred_labs\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
